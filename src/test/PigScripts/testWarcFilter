#!/bin/bash

SCRIPT_DIR=`dirname $0`/../../main/PigScripts/CommandLineUtils
RESOURCE_DIR=`dirname $0`/../resources
DEST_DIR=/tmp/test
#EXEC_MODE=local
EXEC_MODE=mapreduce

TEST_FILE=mixedContent.warc
export TEST_FILE_PATH=$DEST_DIR/$TEST_FILE

# For local or mapreduce mode, make a directory
# in /tmp, and copy the warc test file there.
# Remove possibly left over result from previous run:

mkdir /tmp/test

# Place the test file into the expected directory,
# and remove old result files: 
if [ $EXEC_MODE == local ]
then
  cp $RESOURCE_DIR/$TEST_FILE $DEST_DIR
  rm -rf ${TEST_FILE_PATH}_onlyOne.gz
  rm -rf ${TEST_FILE_PATH}_noSomething.gz
else
  # Will just quietly fail if exists:
  hadoop fs -mkdir /tmp/test
  hadoop fs -copyFromLocal $RESOURCE_DIR/$TEST_FILE $DEST_DIR
  hadoop fs -rmr ${DEST_DIR}/${TEST_FILE}_onlyOne.gz
  hadoop fs -rmr ${DEST_DIR}/${TEST_FILE}_noSomething.gz
fi

# Field name of warc type:
FIELD_NAME_ONLY_ONE_RECORD="WARC-TYPE"
# Regex to keep just one record: the one with warc type 'warcinfo'
REGEX_ONLY_ONE_RECORD=warcinfo

# Field name for content:
FIELD_NAME_CONTENT=content
# (?s): multiline
REGEX_NO_SOMETHING="(?s)(?!.*frankbeecostume).*"


pigrun -x $EXEC_MODE \
        FILTERED_DEST=${TEST_FILE_PATH}_onlyOne.gz \
        WARC_FILE=$TEST_FILE_PATH \
        WARC_FIELD=$FIELD_NAME_ONLY_ONE_RECORD \
        REGEX=$REGEX_ONLY_ONE_RECORD \
        ${SCRIPT_DIR}/warcFilter.pig

pigrun -x $EXEC_MODE \
        FILTERED_DEST=${TEST_FILE_PATH}_noSomething.gz \
        WARC_FILE=$TEST_FILE_PATH \
        WARC_FIELD=$FIELD_NAME_CONTENT \
        REGEX=$REGEX_NO_SOMETHING \
        ${SCRIPT_DIR}/warcFilter.pig

# If ran on mapreduce, then the reference file and
# the generated file to test are on HDFS. Copy them
# the same place they would be for EXEC_MODE local.
# That way Java junit tests can see them:

if [ $EXEC_MODE == mapreduce ]
then
  echo "Removing old test results from local $DEST_DIR..."
  # The reference file :
  cp $RESOURCE_DIR/$TEST_FILE $DEST_DIR
  # rm any old result:
  rm -rf ${TEST_FILE_PATH}_onlyOne.gz
  rm -rf ${TEST_FILE_PATH}_noSomething.gz
  echo "Copying new test results from HDFS to local $DEST_DIR..."
  hadoop fs -copyToLocal ${TEST_FILE_PATH}_onlyOne.gz $DEST_DIR
  hadoop fs -copyToLocal ${TEST_FILE_PATH}_noSomething.gz $DEST_DIR
fi
